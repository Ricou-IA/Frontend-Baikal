// â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
// â•‘  BAIKAL-BRAIN - Routeur SÃ©mantique Intelligent                               â•‘
// â•‘  Edge Function Supabase                                                      â•‘
// â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
// â•‘  Version: 4.4.0 - Classification d'intention + suggestion mode               â•‘
// â•‘  Route vers: BIBLIOTHECAIRE (baikal-librarian) ou ANALYSTE (futur)           â•‘
// â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
// â•‘  NouveautÃ©s v4.4.0:                                                          â•‘
// â•‘  - Nouveau champ "intent" (synthesis, factual, comparison, citation, conv.)  â•‘
// â•‘  - generation_mode devient une SUGGESTION (Librarian peut override)          â•‘
// â•‘  - Prompts GÃ‰NÃ‰RIQUES (spÃ©cialisation mÃ©tier via config.agent_prompts)       â•‘
// â•‘  NouveautÃ©s v4.3.2:                                                          â•‘
// â•‘  - Transmission du project_context Ã  baikal-librarian                        â•‘
// â•‘  NouveautÃ©s v4.3.1:                                                          â•‘
// â•‘  - CORRECTION: .schema('core') sur rÃ©cupÃ©ration identitÃ© projet              â•‘
// â•‘  NouveautÃ©s v4.3.0 (Phase 2):                                                â•‘
// â•‘  - RÃ©cupÃ©ration de l'identitÃ© projet (identity JSONB)                        â•‘
// â•‘  - Formatage et injection dans le prompt via {{project_context}}             â•‘
// â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from "https://esm.sh/@supabase/supabase-js@2"

// ============================================================================
// CONFIGURATION
// ============================================================================

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

const DEFAULT_CONFIG = {
  model: 'gpt-4o-mini',
  temperature: 0,
  max_tokens: 200,
}

// ============================================================================
// PROMPT GÃ‰NÃ‰RIQUE (Fallback - spÃ©cialisation mÃ©tier via DB)
// ============================================================================

const FALLBACK_SYSTEM_PROMPT = `Tu es un routeur intelligent pour un assistant documentaire.
Analyse la question et dÃ©termine:
1. L'INTENTION de l'utilisateur
2. L'agent qui doit traiter la demande
3. Le mode de gÃ©nÃ©ration suggÃ©rÃ©

RÃ‰PONDS UNIQUEMENT en JSON valide, sans markdown ni explication:
{
  "destination": "BIBLIOTHECAIRE",
  "intent": "synthesis",
  "generation_mode": "gemini",
  "reasoning": "explication courte"
}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INTENTIONS POSSIBLES (champ "intent"):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"synthesis" - Demande de vue d'ensemble, rÃ©sumÃ©, explication globale
  â†’ Mots-clÃ©s: rÃ©sume, synthÃ¨se, explique, prÃ©sente, dÃ©cris, c'est quoi ce document
  â†’ Exemples: "RÃ©sume ce document", "Explique-moi ce fichier", "C'est quoi ce rapport ?"

"factual" - Question prÃ©cise sur un fait, chiffre, dÃ©lai, dÃ©finition
  â†’ Mots-clÃ©s: quel est, combien, quand, oÃ¹, dÃ©finition, montant, dÃ©lai, durÃ©e
  â†’ Exemples: "Quel est le dÃ©lai mentionnÃ© ?", "C'est quoi ce terme ?", "Quel montant ?"

"comparison" - Comparaison entre Ã©lÃ©ments, sections, documents
  â†’ Mots-clÃ©s: compare, diffÃ©rence, versus, entre, par rapport Ã 
  â†’ Exemples: "Compare les sections 3 et 7", "DiffÃ©rence entre ces deux documents ?"

"citation" - Demande de citation exacte, rÃ©fÃ©rence prÃ©cise
  â†’ Mots-clÃ©s: cite, article, extrait, texte exact, que dit, selon
  â†’ Exemples: "Cite le passage sur...", "Que dit exactement le document sur..."

"conversational" - Salutation, remerciement, question hors-sujet
  â†’ Exemples: "Bonjour", "Merci", "Comment Ã§a va ?", "Au revoir"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AGENTS (champ "destination"):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BIBLIOTHECAIRE - Pour:
- Documents, normes, rÃ©glementations
- Informations textuelles, dÃ©finitions, procÃ©dures
- Recherche dans la documentation
- Questions gÃ©nÃ©rales nÃ©cessitant des sources

ANALYSTE - Pour:
- Calculs numÃ©riques (quantitÃ©s, coÃ»ts, statistiques)
- Analyse de donnÃ©es chiffrÃ©es
- Tableaux, graphiques
- Traitement de fichiers Excel/CSV

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODE DE GÃ‰NÃ‰RATION (champ "generation_mode"):
Note: C'est une SUGGESTION, le Librarian peut l'adapter selon le volume de pages
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"gemini" - SuggÃ©rÃ© pour:
  - intent = "synthesis" (rÃ©sumÃ©s, vues d'ensemble)
  - intent = "comparison" (besoin de voir plusieurs sections)
  - Analyse approfondie d'un document complet
  - Questions mentionnant un fichier spÃ©cifique par son nom

"chunks" - SuggÃ©rÃ© pour:
  - intent = "factual" (recherche prÃ©cise)
  - intent = "citation" (extrait exact)
  - intent = "conversational" (rÃ©ponse rapide)
  - Questions rapides, dÃ©finitions, informations ponctuelles

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXEMPLES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"RÃ©sume ce document" 
â†’ {"destination":"BIBLIOTHECAIRE","intent":"synthesis","generation_mode":"gemini","reasoning":"demande de rÃ©sumÃ© global"}

"Quel est le dÃ©lai mentionnÃ© Ã  l'article 19 ?"
â†’ {"destination":"BIBLIOTHECAIRE","intent":"factual","generation_mode":"chunks","reasoning":"question prÃ©cise sur un dÃ©lai"}

"C'est quoi ce terme ?"
â†’ {"destination":"BIBLIOTHECAIRE","intent":"factual","generation_mode":"chunks","reasoning":"dÃ©finition demandÃ©e"}

"Compare les sections 3 et 7"
â†’ {"destination":"BIBLIOTHECAIRE","intent":"comparison","generation_mode":"gemini","reasoning":"comparaison nÃ©cessitant lecture des deux"}

"Cite le passage sur les pÃ©nalitÃ©s"
â†’ {"destination":"BIBLIOTHECAIRE","intent":"citation","generation_mode":"chunks","reasoning":"extrait prÃ©cis demandÃ©"}

"Bonjour !"
â†’ {"destination":"BIBLIOTHECAIRE","intent":"conversational","generation_mode":"chunks","reasoning":"salutation"}

"Explique-moi ce document en dÃ©tail"
â†’ {"destination":"BIBLIOTHECAIRE","intent":"synthesis","generation_mode":"gemini","reasoning":"explication dÃ©taillÃ©e demandÃ©e"}

"Calcule les totaux de ce tableau"
â†’ {"destination":"ANALYSTE","intent":"factual","generation_mode":"chunks","reasoning":"calcul numÃ©rique requis"}`

// ============================================================================
// TYPES
// ============================================================================

interface RequestBody {
  query: string
  user_id?: string
  org_id?: string
  project_id?: string
  conversation_id?: string
  app_id?: string
  vertical_id?: string
  match_threshold?: number
  match_count?: number
  generation_mode?: 'chunks' | 'gemini'
}

interface RoutingDecision {
  destination: 'BIBLIOTHECAIRE' | 'ANALYSTE'
  intent: 'synthesis' | 'factual' | 'comparison' | 'citation' | 'conversational'
  generation_mode: 'chunks' | 'gemini'
  reasoning: string
}

interface RouterConfig {
  system_prompt: string
  model: string
  temperature: number
  max_tokens: number
}

interface ProjectIdentity {
  market_type?: string
  project_type?: string
  description?: string
}

// ============================================================================
// FONCTIONS UTILITAIRES
// ============================================================================

function jsonResponse(data: unknown, status = 200): Response {
  return new Response(JSON.stringify(data), {
    status,
    headers: { ...corsHeaders, 'Content-Type': 'application/json' },
  })
}

function errorResponse(message: string, status = 500): Response {
  console.error(`[baikal-brain] Erreur: ${message}`)
  return jsonResponse({ error: message, status: 'error' }, status)
}

// ============================================================================
// FORMATAGE IDENTITÃ‰ PROJET
// ============================================================================

function formatProjectIdentity(identity: ProjectIdentity | null): string {
  if (!identity || Object.keys(identity).length === 0) {
    return 'Aucune identitÃ© projet dÃ©finie.';
  }

  const marketTypeLabels: Record<string, string> = {
    public: 'MarchÃ© Public',
    prive: 'MarchÃ© PrivÃ©',
  };

  const projectTypeLabels: Record<string, string> = {
    entreprise_generale: 'Entreprise GÃ©nÃ©rale',
    macro_lot: 'Macro-Lot',
    gros_oeuvre: 'Gros-Å’uvre',
    lots_techniques: 'Lots Techniques',
    lots_architecturaux: 'Lots Architecturaux',
  };

  const parts: string[] = [];

  if (identity.market_type) {
    const label = marketTypeLabels[identity.market_type] || identity.market_type;
    parts.push(`**Type de marchÃ©**: ${label}`);
  }

  if (identity.project_type) {
    const label = projectTypeLabels[identity.project_type] || identity.project_type;
    parts.push(`**Type de projet**: ${label}`);
  }

  if (identity.description) {
    parts.push(`**Description**: ${identity.description}`);
  }

  return parts.join('\n');
}

async function getProjectIdentity(
  supabase: ReturnType<typeof createClient>,
  project_id: string | undefined
): Promise<string> {
  if (!project_id) {
    return 'Aucune identitÃ© projet.';
  }

  try {
    const { data: project, error } = await supabase
      .schema('core')
      .from('projects')
      .select('identity')
      .eq('id', project_id)
      .single();

    if (error) {
      console.warn(`[baikal-brain] Erreur rÃ©cupÃ©ration identitÃ© projet: ${error.message}`);
      return 'Aucune identitÃ© projet.';
    }

    if (!project || !project.identity) {
      return 'Aucune identitÃ© projet dÃ©finie.';
    }

    return formatProjectIdentity(project.identity as ProjectIdentity);
  } catch (error) {
    console.warn(`[baikal-brain] Erreur formatage identitÃ©: ${error}`);
    return 'Aucune identitÃ© projet.';
  }
}

// ============================================================================
// RÃ‰CUPÃ‰RATION CONFIG ROUTEUR DEPUIS DB
// ============================================================================

async function getRouterConfig(
  supabase: ReturnType<typeof createClient>,
  app_id: string,
  org_id?: string
): Promise<RouterConfig> {
  console.log(`[baikal-brain] Recherche prompt routeur pour app=${app_id}, org=${org_id || 'null'}`)
  
  // PrioritÃ© 1: Prompt spÃ©cifique Ã  l'organisation
  if (org_id) {
    const { data: orgPrompt } = await supabase
      .schema('config')
      .from('agent_prompts')
      .select('system_prompt, parameters')
      .eq('agent_type', 'router')
      .eq('is_active', true)
      .eq('org_id', org_id)
      .single()
    
    if (orgPrompt) {
      console.log('[baikal-brain] Prompt routeur trouvÃ©: niveau organisation')
      return {
        system_prompt: orgPrompt.system_prompt,
        model: orgPrompt.parameters?.model || DEFAULT_CONFIG.model,
        temperature: orgPrompt.parameters?.temperature ?? DEFAULT_CONFIG.temperature,
        max_tokens: orgPrompt.parameters?.max_tokens || DEFAULT_CONFIG.max_tokens,
      }
    }
  }
  
  // PrioritÃ© 2: Prompt spÃ©cifique Ã  la verticale (app_id)
  const { data: appPrompt } = await supabase
    .schema('config')
    .from('agent_prompts')
    .select('system_prompt, parameters')
    .eq('agent_type', 'router')
    .eq('is_active', true)
    .eq('app_id', app_id)
    .is('org_id', null)
    .single()
  
  if (appPrompt) {
    console.log('[baikal-brain] Prompt routeur trouvÃ©: niveau verticale')
    return {
      system_prompt: appPrompt.system_prompt,
      model: appPrompt.parameters?.model || DEFAULT_CONFIG.model,
      temperature: appPrompt.parameters?.temperature ?? DEFAULT_CONFIG.temperature,
      max_tokens: appPrompt.parameters?.max_tokens || DEFAULT_CONFIG.max_tokens,
    }
  }
  
  // PrioritÃ© 3: Prompt global
  const { data: globalPrompt } = await supabase
    .schema('config')
    .from('agent_prompts')
    .select('system_prompt, parameters')
    .eq('agent_type', 'router')
    .eq('is_active', true)
    .is('app_id', null)
    .is('org_id', null)
    .single()
  
  if (globalPrompt) {
    console.log('[baikal-brain] Prompt routeur trouvÃ©: niveau global')
    return {
      system_prompt: globalPrompt.system_prompt,
      model: globalPrompt.parameters?.model || DEFAULT_CONFIG.model,
      temperature: globalPrompt.parameters?.temperature ?? DEFAULT_CONFIG.temperature,
      max_tokens: globalPrompt.parameters?.max_tokens || DEFAULT_CONFIG.max_tokens,
    }
  }
  
  console.log('[baikal-brain] Aucun prompt routeur en DB, utilisation du fallback gÃ©nÃ©rique')
  return {
    system_prompt: FALLBACK_SYSTEM_PROMPT,
    model: DEFAULT_CONFIG.model,
    temperature: DEFAULT_CONFIG.temperature,
    max_tokens: DEFAULT_CONFIG.max_tokens,
  }
}

// ============================================================================
// ROUTAGE SÃ‰MANTIQUE v4.4.0
// ============================================================================

async function routeQuery(
  query: string, 
  openaiApiKey: string,
  config: RouterConfig,
  projectContext: string
): Promise<RoutingDecision> {
  console.log(`[baikal-brain] Routage avec model=${config.model}, temp=${config.temperature}`)
  
  const systemPromptWithContext = config.system_prompt
    .replace('{{project_context}}', projectContext);
  
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${openaiApiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: config.model,
      temperature: config.temperature,
      max_tokens: config.max_tokens,
      messages: [
        { role: 'system', content: systemPromptWithContext },
        { role: 'user', content: query }
      ],
    }),
  })

  if (!response.ok) {
    throw new Error(`OpenAI routing error: ${response.status}`)
  }

  const data = await response.json()
  const content = data.choices?.[0]?.message?.content || ''

  try {
    // Nettoyer le JSON (parfois entourÃ© de ```)
    const cleanContent = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim()
    const parsed = JSON.parse(cleanContent) as RoutingDecision
    return {
      destination: parsed.destination || 'BIBLIOTHECAIRE',
      intent: parsed.intent || 'factual',
      generation_mode: parsed.generation_mode || 'chunks',
      reasoning: parsed.reasoning || 'aucune raison fournie'
    }
  } catch {
    console.warn(`[baikal-brain] Erreur parsing JSON: ${content}`)
    return { 
      destination: 'BIBLIOTHECAIRE',
      intent: 'factual',
      generation_mode: 'chunks',
      reasoning: 'fallback - erreur parsing' 
    }
  }
}

// ============================================================================
// APPEL AGENT BIBLIOTHÃ‰CAIRE v4.4.0
// ============================================================================

async function callLibrarian(
  body: RequestBody,
  decision: RoutingDecision,
  supabaseUrl: string, 
  authHeader: string,
  apiKey: string,
  projectContext: string
): Promise<Response> {
  const librarianUrl = `${supabaseUrl}/functions/v1/baikal-librarian`
  
  console.log(`[baikal-brain] Appel du BibliothÃ©caire: ${librarianUrl}`)
  console.log(`[baikal-brain] user_id: ${body.user_id}`)
  console.log(`[baikal-brain] project_id: ${body.project_id || 'aucun'}`)
  console.log(`[baikal-brain] conversation_id: ${body.conversation_id || 'nouvelle conversation'}`)
  console.log(`[baikal-brain] intent: ${decision.intent}`)
  console.log(`[baikal-brain] generation_mode (suggestion): ${decision.generation_mode}`)
  console.log(`[baikal-brain] project_context (${projectContext.length} chars)`)
  
  // v4.4.0: Transmet l'intent au Librarian
  const normalizedBody = {
    ...body,
    app_id: body.app_id || body.vertical_id,
    generation_mode: body.generation_mode || decision.generation_mode,
    intent: decision.intent,
    project_context: projectContext,
  }
  
  const response = await fetch(librarianUrl, {
    method: 'POST',
    headers: {
      'Authorization': authHeader,
      'apikey': apiKey,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(normalizedBody),
  })

  const data = await response.json()
  return jsonResponse({
    ...data,
    routed_to: 'BIBLIOTHECAIRE',
    intent: decision.intent,
    suggested_mode: decision.generation_mode,
    routing_reasoning: decision.reasoning
  }, response.status)
}

// ============================================================================
// FONCTION PRINCIPALE
// ============================================================================

serve(async (req: Request): Promise<Response> => {
  const startTime = Date.now()

  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  if (req.method !== 'POST') {
    return errorResponse('MÃ©thode non autorisÃ©e. Utilisez POST.', 405)
  }

  try {
    // ========================================
    // 1. VALIDATION
    // ========================================
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY')
    const supabaseUrl = Deno.env.get('SUPABASE_URL')
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
    
    if (!openaiApiKey) {
      return errorResponse('OPENAI_API_KEY manquant', 500)
    }
    if (!supabaseUrl || !supabaseServiceKey) {
      return errorResponse('SUPABASE_URL ou SUPABASE_SERVICE_ROLE_KEY manquant', 500)
    }

    const authHeader = req.headers.get('Authorization') || ''
    const apiKey = req.headers.get('apikey') || ''

    const body: RequestBody = await req.json()
    const { query, user_id, org_id, project_id, conversation_id, generation_mode: clientMode } = body

    if (!query || query.trim().length === 0) {
      return errorResponse('Le champ "query" est requis', 400)
    }

    const effectiveAppId = body.app_id || body.vertical_id || 'arpet'

    console.log(`[baikal-brain] v4.4.0 - Classification d'intention + suggestion mode`)
    console.log(`[baikal-brain] RequÃªte: "${query.substring(0, 80)}..."`)
    console.log(`[baikal-brain] user_id: ${user_id}, project_id: ${project_id || 'aucun'}`)
    console.log(`[baikal-brain] conversation_id: ${conversation_id || 'nouvelle conversation'}`)
    if (clientMode) {
      console.log(`[baikal-brain] Mode forcÃ© par client: ${clientMode}`)
    }

    // ========================================
    // 2. INITIALISER SUPABASE CLIENT
    // ========================================
    const supabase = createClient(supabaseUrl, supabaseServiceKey)

    // ========================================
    // 3. RÃ‰CUPÃ‰RER IDENTITÃ‰ PROJET
    // ========================================
    const projectContext = await getProjectIdentity(supabase, project_id)
    console.log(`[baikal-brain] Contexte projet: ${projectContext.substring(0, 100)}...`)

    // ========================================
    // 4. RÃ‰CUPÃ‰RER CONFIG ROUTEUR
    // ========================================
    const routerConfig = await getRouterConfig(supabase, effectiveAppId, org_id)

    // ========================================
    // 5. ROUTAGE SÃ‰MANTIQUE
    // ========================================
    console.log('[baikal-brain] Analyse du routage...')
    const decision = await routeQuery(query, openaiApiKey, routerConfig, projectContext)
    console.log(`[baikal-brain] DÃ©cision: ${decision.destination} | Intent: ${decision.intent} | Mode suggÃ©rÃ©: ${decision.generation_mode}`)
    console.log(`[baikal-brain] Raison: ${decision.reasoning}`)

    // ========================================
    // 6. DÃ‰LÃ‰GATION Ã€ L'AGENT
    // ========================================
    if (decision.destination === 'BIBLIOTHECAIRE') {
      return await callLibrarian(body, decision, supabaseUrl, authHeader, apiKey, projectContext)
    } 
    else if (decision.destination === 'ANALYSTE') {
      return jsonResponse({
        response: "ğŸš§ L'Agent Analyste est en cours de dÃ©veloppement. Pour les calculs et analyses de donnÃ©es, cette fonctionnalitÃ© sera bientÃ´t disponible.",
        sources: [],
        routed_to: 'ANALYSTE',
        intent: decision.intent,
        generation_mode: decision.generation_mode,
        status: 'not_implemented',
        reasoning: decision.reasoning,
        processing_time_ms: Date.now() - startTime
      })
    }

    // Fallback
    return await callLibrarian(body, decision, supabaseUrl, authHeader, apiKey, projectContext)

  } catch (error) {
    console.error('[baikal-brain] Erreur non gÃ©rÃ©e:', error)
    return errorResponse(String(error), 500)
  }
})
